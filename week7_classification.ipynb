{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Logistic Regression and Classification\n",
    "### Spring 2022, Week 7\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr22/week7_logisticregression\n",
    "!mkdir ./data\n",
    "!cp week7_logisticregression/data/* ./data\n",
    "!cp week7_logisticregression/clean_data.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sklearn import linear_model, neighbors, svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, f1_score, roc_curve, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (10,10)\n",
    "COLORS= [\"#008080\",\"#CA562C\"]\n",
    "\n",
    "sns.set(font_scale=1, rc={'figure.figsize':FIG_SIZE}) \n",
    "sns.set_style(\"white\",  {'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
    "plt.rc(\"axes.spines\", top=False, right=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuition towards sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sigmoid function\n",
    "def sigmoid(t):\n",
    "    return 1/(1 + np.exp(-t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(beta_0 = (-2,2), beta_1 = (0.5,5))\n",
    "def plot_logistic(beta_0=0, beta_1=2):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    x = np.linspace(-10, 10)\n",
    "    plt.plot(x, sigmoid(x), label = r\"$\\beta_0 = 0, \\beta_1=1$\")\n",
    "    plt.plot(x, sigmoid(beta_0+beta_1*x), label = r\"$\\beta_0 = {}, \\beta_1={}$\".format(beta_0, beta_1))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=LABEL_FONT)\n",
    "    plt.title(r\"$t = \\beta_0 + \\beta_1 x$\", fontsize=TITLE_FONT)\n",
    "    plt.text(-9, 1, r\"$\\sigma(x) = \\frac{1}{1+e^{-t}}$\", \n",
    "             ha=\"left\", va=\"top\",\n",
    "             fontsize=LABEL_FONT,\n",
    "             bbox=dict(boxstyle=\"square\",\n",
    "                   ec=(1., 0.5, 0.5),\n",
    "                   fc=(1., 0.8, 0.8),\n",
    "                   )\n",
    "             )\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y    \", rotation=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification(X,Y):\n",
    "    colors = [COLORS[y] for y in Y]\n",
    "    pl.scatter(X[:,0], X[:,1], marker='o',c=colors)\n",
    "X, Y = make_classification(n_samples=201, n_features=2, n_redundant=0, class_sep=.9, random_state=111)\n",
    "plot_classification(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color maps\n",
    "cmap_light = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "def visualize_classification_model(model, X,Y, step_size = .02, title=\"\", cont=False):\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, step_size),\n",
    "    np.arange(y_min, y_max, step_size))\n",
    "    \n",
    "    if not cont:\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else: \n",
    "        temp_Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = temp_Z[:,1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light, alpha=.3)\n",
    "    colors = [COLORS[y] for y in Y]\n",
    "    pl.scatter(X[:,0], X[:,1], marker='o',c=colors, edgecolor=\"k\")\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(title, fontsize=TITLE_FONT)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\",  {'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
    "def plot_logisticRegressionClassifier(X, Y):\n",
    "    model = linear_model.LogisticRegression(penalty='none')\n",
    "    title_string = f\"Logistic Regression (no regularization)\"\n",
    "    visualize_classification_model(model, X, Y, title=title_string, cont=True)\n",
    "\n",
    "def plot_svmClassifier(kernel, C, X, Y):\n",
    "    model = svm.SVC(kernel=kernel)\n",
    "    title_string = f\"Support Vector Machine Classifier (kernel = {kernel}, C = {C})\"\n",
    "    visualize_classification_model(model, X, Y, title=title_string, cont=False)\n",
    "    \n",
    "def plot_nearestNeighborsClassifier(n_neighbors, X, Y):\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "    title_string = f\"Nearest Neighbors (K = {n_neighbors})\"\n",
    "    visualize_classification_model(model, X, Y, title=title_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_logisticRegressionClassifier(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(kernel=[\"linear\", \"poly\", \"rbf\", \"sigmoid\"], C=(0.1,2.0))\n",
    "def SVM_wrapper(kernel=\"linear\", C=1):\n",
    "    plot_svmClassifier(kernel, C, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(K=(1, X.shape[0]))\n",
    "def KNN_wrapper(K=5):\n",
    "    plot_nearestNeighborsClassifier(K, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(model, X,Y, title=\"\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=model.classes_,\n",
    "        cmap=plt.cm.Blues)\n",
    "    try:\n",
    "        score = f1_score(y_test, model.predict(X_test))\n",
    "    except ValueError:\n",
    "        y_test_binary = [1 if y == \"M\" else 0 for y in y_test]\n",
    "        y_pred_binary = [1 if y == \"M\" else 0 for y in model.predict(X_test)]\n",
    "        score = f1_score(y_test_binary, y_pred_binary)\n",
    "    disp.ax_.set_title(title + r\"  $F_1$ score = {0:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_logisticRegressionClassifier(X, Y, plot=True):\n",
    "    model = linear_model.LogisticRegression(penalty='none')\n",
    "    title_string = f\"Logistic Regression (no regularization)\"\n",
    "    if plot: visualize_classification_model(model, X, Y, title=title_string, cont=True)\n",
    "    confusion_matrix(model, X, Y, title=title_string)\n",
    "\n",
    "def confusion_svmClassifier(kernel, C, X, Y, plot=True):\n",
    "    model = svm.SVC(kernel=kernel)\n",
    "    title_string = f\"Support Vector Machine Classifier (kernel = {kernel}, C = {C})\"\n",
    "    if plot: visualize_classification_model(model, X, Y, title=title_string, cont=False)\n",
    "    confusion_matrix(model, X, Y, title=title_string)\n",
    "    \n",
    "def confusion_nearestNeighborsClassifier(n_neighbors, X, Y, plot=True):\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "    title_string = f\"Nearest Neighbors (K = {n_neighbors})\"\n",
    "    if plot: visualize_classification_model(model, X, Y, title=title_string, cont=False)\n",
    "    confusion_matrix(model, X, Y, title=title_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ F_1 = \\frac{TP}{TP + 1/2(FP+FN)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_logisticRegressionClassifier(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(kernel=[\"linear\", \"poly\", \"rbf\", \"sigmoid\"], C=(0,2))\n",
    "def SVM_wrapper(kernel=\"linear\", C=1):\n",
    "    confusion_svmClassifier(kernel, C, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(K=(1, X.shape[0]))\n",
    "def KNN_wrapper(K=5):\n",
    "    confusion_nearestNeighborsClassifier(K, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reciever Operator Curve\n",
    "\n",
    "Or why is it important that logistic regression outputs a probability rather than a class? \n",
    "\n",
    "![roc](roc_curve.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_roc_curve(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=0)\n",
    "    clf = linear_model.LogisticRegression(penalty='l2', C=0.1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
    "    \n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    except ValueError:\n",
    "        y_test_binary = [1 if y == \"M\" else 0 for y in y_test]\n",
    "        fpr, tpr, _ = roc_curve(y_test_binary,  y_pred_proba)\n",
    "        auc = roc_auc_score(y_test_binary, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr,tpr,label=\"auc= {0:.2f}\".format(auc))\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.plot([0,1], [0,1], \"k--\", label = \"Random Model\")\n",
    "    plt.plot([0,0,1], [0,1,1], \"k:\", label = \"Ideal Model\")\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_roc_curve(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Classwork:\n",
    "\n",
    "### We are going to use the Wisconsin Diagnostic Breast Cancer dataset once again\n",
    "\n",
    "From the data source: Wisconsin Diagnostic Breast Cancer (WDBC)\n",
    "\n",
    "```\n",
    "\tFeatures are computed from a digitized image of a fine needle\n",
    "\taspirate (FNA) of a breast mass.  They describe\n",
    "\tcharacteristics of the cell nuclei present in the image.\n",
    "\tA few of the images can be found at\n",
    "\thttp://www.cs.wisc.edu/~street/images/\n",
    "\n",
    "\tSeparating plane described above was obtained using\n",
    "\tMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
    "\tConstruction Via Linear Programming.\" Proceedings of the 4th\n",
    "\tMidwest Artificial Intelligence and Cognitive Science Society,\n",
    "\tpp. 97-101, 1992], a classification method which uses linear\n",
    "\tprogramming to construct a decision tree.  Relevant features\n",
    "\twere selected using an exhaustive search in the space of 1-4\n",
    "\tfeatures and 1-3 separating planes.\n",
    "\n",
    "\tThe actual linear program used to obtain the separating plane\n",
    "\tin the 3-dimensional space is that described in:\n",
    "\t[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
    "\tProgramming Discrimination of Two Linearly Inseparable Sets\",\n",
    "\tOptimization Methods and Software 1, 1992, 23-34].\n",
    "    \n",
    "    Source:\n",
    "    W.N. Street, W.H. Wolberg and O.L. Mangasarian \n",
    "\tNuclear feature extraction for breast tumor diagnosis.\n",
    "\tIS&T/SPIE 1993 International Symposium on Electronic Imaging: Science\n",
    "\tand Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
    "```\n",
    "\n",
    "What do all the column names mean?\n",
    "\n",
    "- ID number\n",
    "- Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry \n",
    "- fractal dimension (\"coastline approximation\" - 1) - a measure of \"complexity\" of a 2D image.\n",
    "\n",
    "\n",
    "Cateogory Distribution: 357 benign, 212 malignant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_data\n",
    "\n",
    "original_cancer_dataset = clean_data.generate_clean_dataframe()\n",
    "original_cancer_dataset.reset_index(inplace=True)\n",
    "cancer_Y = original_cancer_dataset[\"diagnosis\"]\n",
    "cancer_X = original_cancer_dataset.drop([\"ID\", \"diagnosis\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cancer_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_logisticRegressionClassifier(cancer_X,cancer_Y, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(kernel=[\"linear\", \"poly\", \"rbf\", \"sigmoid\"], C=(0,2))\n",
    "def SVM_wrapper(kernel=\"linear\", C=1):\n",
    "    confusion_svmClassifier(kernel, C, cancer_X,cancer_Y, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(K=(1, X.shape[0]))\n",
    "def KNN_wrapper(K=5):\n",
    "    confusion_nearestNeighborsClassifier(K, cancer_X,cancer_Y, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_roc_curve(cancer_X,cancer_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
